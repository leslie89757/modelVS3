"""é«˜çº§Agentæ‰§è¡Œå¼•æ“"""

import json
import asyncio
import time
import random
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
from sqlalchemy.orm import Session

from ..models_advanced import (
    AdvancedAgent, AgentSession, SessionMessage, AdvancedTool,
    AgentMemory, AgentKnowledgeBase, AdvancedAgentStatus
)
from ..models import Model
from .llm_adapters import llm_factory
from .advanced_tool_executor import AdvancedToolExecutor
from .advanced_memory_manager import AdvancedMemoryManager

logger = logging.getLogger(__name__)


class AdvancedAgentExecutor:
    """é«˜çº§Agentæ‰§è¡Œå¼•æ“"""
    
    def __init__(self, db: Optional[Session] = None):
        self.db = db
        self.tool_executor = AdvancedToolExecutor(db)
        self.memory_manager = AdvancedMemoryManager(db)
    
    async def process_message(
        self,
        agent: AdvancedAgent,
        session: AgentSession,
        message: str,
        message_history: List[Dict[str, Any]],
        include_reasoning: bool = True,
        max_iterations: int = 10
    ) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›Agentå“åº”"""
        
        try:
            # è·å–Agenté…ç½®
            config = agent.config or {}
            autonomy_level = config.get("autonomy_level", "semi_autonomous")
            transparency = config.get("transparency", "high")
            memory_enabled = config.get("memory_enabled", True)
            
            # è·å–æ¨¡å‹é…ç½®
            model_id = config.get("primary_model")
            if not model_id:
                raise ValueError("Agentæ²¡æœ‰é…ç½®ä¸»è¦æ¨¡å‹")
            
            model_config = await self._get_model_config(model_id)
            
            # è·å–LLMé€‚é…å™¨
            llm_adapter = await llm_factory.get_adapter(
                model_name=model_config["name"],
                endpoint=model_config["endpoint"],
                provider=model_config["provider"],
                api_key=model_config.get("api_key"),
                custom_headers=model_config.get("custom_headers")
            )
            
            # å‡†å¤‡å¯¹è¯ä¸Šä¸‹æ–‡
            context = await self._prepare_context(agent, session, message_history, memory_enabled)
            
            # æ‰§è¡ŒReActå¾ªç¯
            result = await self._execute_react_loop(
                agent=agent,
                session=session,
                llm_adapter=llm_adapter,
                user_message=message,
                context=context,
                max_iterations=max_iterations,
                include_reasoning=include_reasoning,
                autonomy_level=autonomy_level
            )
            
            # æ›´æ–°è®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if memory_enabled:
                await self._update_memory(agent, session, message, result)
            
            return result
            
        except Exception as e:
            logger.error(f"Agentå¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            return {
                "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°é”™è¯¯: {str(e)}",
                "confidence": 0.1,
                "reasoning": f"ç³»ç»Ÿé”™è¯¯: {str(e)}" if include_reasoning else None,
                "tool_calls": None,
                "metadata": {"error": True, "error_message": str(e)},
                "tokens_used": 0,
                "cost": 0.0
            }
    
    async def _execute_react_loop(
        self,
        agent: AdvancedAgent,
        session: AgentSession,
        llm_adapter: Any,
        user_message: str,
        context: Dict[str, Any],
        max_iterations: int,
        include_reasoning: bool,
        autonomy_level: str
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒReActæ¨ç†å¾ªç¯"""
        
        iteration = 0
        total_tokens = 0
        total_cost = 0.0
        reasoning_steps = []
        tool_calls = []
        confidence_scores = []
        
        # æ„å»ºåˆå§‹æç¤ºè¯
        system_prompt = self._build_system_prompt(agent, context, autonomy_level)
        
        # åˆå§‹åŒ–æ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å†å²æ¶ˆæ¯
        for msg in context.get("recent_messages", []):
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user", 
            "content": user_message
        })
        
        while iteration < max_iterations:
            iteration += 1
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            if self.db:
                session.current_step = f"æ¨ç†å¾ªç¯ {iteration}/{max_iterations}"
                session.progress = int((iteration / max_iterations) * 80)  # 80%ä¸ºæ¨ç†è¿›åº¦
                self.db.commit()
            
            try:
                # è°ƒç”¨LLMè¿›è¡Œæ¨ç†
                logger.info(f"Agent {agent.name} - æ¨ç†å¾ªç¯ {iteration}")
                
                # æ ¹æ®è‡ªä¸»æ°´å¹³è°ƒæ•´æç¤º
                if autonomy_level == "guided":
                    prompt_suffix = "\n\nè¯·é€æ­¥æ€è€ƒå¹¶æ˜ç¡®è¯´æ˜æ¯ä¸ªæ­¥éª¤ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·è¯¦ç»†è¯´æ˜åŸå› ã€‚"
                elif autonomy_level == "semi_autonomous":
                    prompt_suffix = "\n\nè¯·æ€è€ƒè§£å†³æ–¹æ¡ˆå¹¶åœ¨éœ€è¦æ—¶ä½¿ç”¨é€‚å½“çš„å·¥å…·ã€‚"
                else:  # autonomous
                    prompt_suffix = "\n\nè¯·è‡ªä¸»åˆ†æå¹¶æ‰§è¡Œå¿…è¦çš„æ“ä½œæ¥å®Œæˆä»»åŠ¡ã€‚"
                
                current_messages = messages + [{
                    "role": "user",
                    "content": f"å½“å‰æ˜¯ç¬¬{iteration}è½®æ¨ç†ã€‚{prompt_suffix}"
                }]
                
                # è·å–å¯ç”¨å·¥å…·
                available_tools = await self._get_available_tools(agent)
                
                response = await llm_adapter.chat_completion(
                    messages=current_messages,
                    temperature=0.7,
                    max_tokens=2000,
                    tools=available_tools if available_tools else None
                )
                
                total_tokens += response.get("usage", {}).get("total_tokens", 0)
                total_cost += response.get("cost", 0.0)
                
                # è§£æå“åº”
                content = response.get("content", "")
                tool_calls_in_response = response.get("tool_calls", [])
                
                # è®°å½•æ¨ç†æ­¥éª¤
                reasoning_step = {
                    "iteration": iteration,
                    "thought": content,
                    "tool_calls": tool_calls_in_response,
                    "timestamp": datetime.now().isoformat()
                }
                reasoning_steps.append(reasoning_step)
                
                # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": content,
                    "tool_calls": tool_calls_in_response
                })
                
                # è®¡ç®—ä¿¡å¿ƒåº¦
                confidence = self._calculate_confidence(content, tool_calls_in_response, iteration, max_iterations)
                confidence_scores.append(confidence)
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
                if tool_calls_in_response:
                    logger.info(f"æ‰§è¡Œ {len(tool_calls_in_response)} ä¸ªå·¥å…·è°ƒç”¨")
                    
                    for tool_call in tool_calls_in_response:
                        try:
                            # æ‰§è¡Œå·¥å…·
                            tool_result = await self.tool_executor.execute_tool(
                                tool_name=tool_call["function"]["name"],
                                parameters=json.loads(tool_call["function"]["arguments"]),
                                agent_id=str(agent.id)
                            )
                            
                            # è®°å½•å·¥å…·è°ƒç”¨
                            tool_call_record = {
                                "id": tool_call["id"],
                                "name": tool_call["function"]["name"],
                                "arguments": json.loads(tool_call["function"]["arguments"]),
                                "result": tool_result,
                                "status": "success" if tool_result.get("success") else "error",
                                "execution_time": tool_result.get("execution_time", 0)
                            }
                            tool_calls.append(tool_call_record)
                            
                            # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call["id"],
                                "content": json.dumps(tool_result, ensure_ascii=False)
                            })
                            
                        except Exception as e:
                            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                            # è®°å½•å·¥å…·æ‰§è¡Œå¤±è´¥
                            tool_call_record = {
                                "id": tool_call["id"],
                                "name": tool_call["function"]["name"],
                                "arguments": json.loads(tool_call["function"]["arguments"]),
                                "result": {"error": str(e)},
                                "status": "error",
                                "execution_time": 0
                            }
                            tool_calls.append(tool_call_record)
                            
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call["id"],
                                "content": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                            })
                    
                    # å¦‚æœæ˜¯å¼•å¯¼æ¨¡å¼ï¼Œåœ¨å·¥å…·æ‰§è¡Œåæš‚åœç­‰å¾…ç¡®è®¤
                    if autonomy_level == "guided" and self.db:
                        session.current_step = "ç­‰å¾…ç”¨æˆ·ç¡®è®¤å·¥å…·æ‰§è¡Œç»“æœ"
                        self.db.commit()
                
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²å®Œæˆä»»åŠ¡
                    if self._is_task_completed(content, iteration):
                        logger.info(f"ä»»åŠ¡å®Œæˆäºç¬¬{iteration}è½®")
                        break
                
            except Exception as e:
                logger.error(f"æ¨ç†å¾ªç¯ç¬¬{iteration}è½®å¤±è´¥: {e}")
                reasoning_steps.append({
                    "iteration": iteration,
                    "thought": f"æ¨ç†å¤±è´¥: {str(e)}",
                    "error": True,
                    "timestamp": datetime.now().isoformat()
                })
                break
        
        # ç”Ÿæˆæœ€ç»ˆå“åº”
        final_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5
        
        # æ„å»ºæœ€ç»ˆå†…å®¹
        if reasoning_steps:
            last_step = reasoning_steps[-1]
            final_content = last_step.get("thought", "å¤„ç†å®Œæˆ")
        else:
            final_content = "æŠ±æ­‰ï¼Œæ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
        
        # æ„å»ºæ¨ç†è¿‡ç¨‹æ€»ç»“
        reasoning_summary = None
        if include_reasoning and reasoning_steps:
            reasoning_summary = self._build_reasoning_summary(reasoning_steps, tool_calls)
        
        # æ›´æ–°æœ€ç»ˆè¿›åº¦
        if self.db:
            session.current_step = "å®Œæˆ"
            session.progress = 100
            session.confidence_score = final_confidence
            self.db.commit()
        
        return {
            "content": final_content,
            "confidence": final_confidence,
            "reasoning": reasoning_summary,
            "tool_calls": tool_calls if tool_calls else None,
            "metadata": {
                "iterations": iteration,
                "total_reasoning_steps": len(reasoning_steps),
                "total_tool_calls": len(tool_calls),
                "autonomy_level": autonomy_level
            },
            "tokens_used": total_tokens,
            "cost": total_cost
        }
    
    def _build_system_prompt(self, agent: AdvancedAgent, context: Dict[str, Any], autonomy_level: str) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        
        # è·å–è§’è‰²ä¿¡æ¯
        from ..schemas_advanced import AGENT_ROLES
        role_info = next((r for r in AGENT_ROLES if r["id"] == agent.role), None)
        role_name = role_info["name"] if role_info else "AIåŠ©æ‰‹"
        role_desc = role_info["description"] if role_info else "æ™ºèƒ½åŠ©æ‰‹"
        
        # åŸºç¡€æç¤ºè¯
        prompt = f"""ä½ æ˜¯{role_name}ï¼Œ{role_desc}ã€‚

ä¸ªæ€§ç‰¹ç‚¹: {agent.personality}
ç”¨æˆ·å¯¹ä½ çš„æœŸæœ›: {agent.description or 'æä¾›ä¸“ä¸šçš„å¸®åŠ©å’Œå»ºè®®'}

ä½ çš„å·¥ä½œæ–¹å¼:
"""
        
        # æ ¹æ®è‡ªä¸»æ°´å¹³è°ƒæ•´æç¤º
        if autonomy_level == "guided":
            prompt += """
- æ¯ä¸€æ­¥éƒ½è¦è¯¦ç»†è¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹
- åœ¨ä½¿ç”¨ä»»ä½•å·¥å…·å‰éƒ½è¦æ˜ç¡®è¯´æ˜åŸå› å’Œç›®çš„
- ç­‰å¾…ç”¨æˆ·ç¡®è®¤åå†ç»§ç»­ä¸‹ä¸€æ­¥
- ä¿æŒè°¨æ…ï¼Œé¿å…åšå‡ºå¯èƒ½å½±å“ç”¨æˆ·çš„å†³ç­–
"""
        elif autonomy_level == "semi_autonomous":
            prompt += """
- å¯ä»¥è‡ªä¸»åˆ†æé—®é¢˜å¹¶åˆ¶å®šè§£å†³æ–¹æ¡ˆ
- åœ¨å…³é”®å†³ç­–ç‚¹ä¼šè¯¢é—®ç”¨æˆ·æ„è§
- ä½¿ç”¨å·¥å…·æ—¶ä¼šè¯´æ˜ç›®çš„å’Œé¢„æœŸç»“æœ
- åœ¨ä¸ç¡®å®šæ—¶ä¼šå¯»æ±‚ç”¨æˆ·æŒ‡å¯¼
"""
        else:  # autonomous
            prompt += """
- å®Œå…¨è‡ªä¸»åˆ†æå’Œè§£å†³é—®é¢˜
- æ ¹æ®éœ€è¦é€‰æ‹©å’Œä½¿ç”¨é€‚å½“çš„å·¥å…·
- ä¸“æ³¨äºé«˜æ•ˆå®Œæˆç”¨æˆ·çš„ç›®æ ‡
- åœ¨é‡åˆ°é‡å¤§é—®é¢˜æ—¶æ‰ä¼šå¯»æ±‚å¸®åŠ©
"""
        
        # æ·»åŠ è®°å¿†ä¿¡æ¯
        if context.get("relevant_memories"):
            prompt += f"\n\nç›¸å…³è®°å¿†ä¿¡æ¯:\n{context['relevant_memories']}"
        
        # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯
        if context.get("knowledge_base"):
            prompt += f"\n\nä¸“ä¸šçŸ¥è¯†:\n{context['knowledge_base']}"
        
        # æ·»åŠ å¯ç”¨å·¥å…·ä¿¡æ¯
        if context.get("available_tools"):
            prompt += f"\n\nå¯ç”¨å·¥å…·: {', '.join(context['available_tools'])}"
        
        prompt += f"""

è¯·å§‹ç»ˆä¿æŒ{agent.personality}çš„é£æ ¼ï¼Œç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚
å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        return prompt
    
    def _calculate_confidence(self, content: str, tool_calls: List[Dict], iteration: int, max_iterations: int) -> float:
        """è®¡ç®—ä¿¡å¿ƒåº¦"""
        
        confidence = 0.5  # åŸºç¡€ä¿¡å¿ƒåº¦
        
        # æ ¹æ®å†…å®¹é•¿åº¦è°ƒæ•´
        if len(content) > 100:
            confidence += 0.1
        if len(content) > 300:
            confidence += 0.1
        
        # æ ¹æ®å·¥å…·ä½¿ç”¨æƒ…å†µè°ƒæ•´
        if tool_calls:
            confidence += 0.2  # ä½¿ç”¨å·¥å…·é€šå¸¸æ„å‘³ç€æ›´è¯¦ç»†çš„å¤„ç†
        
        # æ ¹æ®è¿­ä»£è½®æ¬¡è°ƒæ•´
        if iteration <= max_iterations * 0.5:
            confidence += 0.1  # æ—©æœŸå®Œæˆä»»åŠ¡é€šå¸¸æ„å‘³ç€æ˜ç¡®çš„è§£å†³æ–¹æ¡ˆ
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç¡®å®šæ€§è¯æ±‡
        uncertainty_words = ["å¯èƒ½", "ä¹Ÿè®¸", "å¤§æ¦‚", "ä¸ç¡®å®š", "ä¸æ¸…æ¥š", "å¯èƒ½éœ€è¦"]
        for word in uncertainty_words:
            if word in content:
                confidence -= 0.1
                break
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‚¯å®šæ€§è¯æ±‡
        certainty_words = ["ç¡®å®š", "æ˜ç¡®", "æ¸…æ¥š", "è‚¯å®š", "å®Œæˆ", "å·²è§£å†³"]
        for word in certainty_words:
            if word in content:
                confidence += 0.1
                break
        
        # é™åˆ¶åœ¨0.1-1.0ä¹‹é—´
        return max(0.1, min(1.0, confidence))
    
    def _is_task_completed(self, content: str, iteration: int) -> bool:
        """åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        
        # æ£€æŸ¥å®Œæˆæ ‡å¿—è¯
        completion_indicators = [
            "å®Œæˆ", "ç»“æŸ", "å·²è§£å†³", "å·²å¤„ç†", "æå®š", 
            "æ²¡æœ‰å…¶ä»–", "å·²ç»å›ç­”", "å¸Œæœ›æœ‰å¸®åŠ©", "è¿˜æœ‰å…¶ä»–é—®é¢˜å—"
        ]
        
        for indicator in completion_indicators:
            if indicator in content:
                return True
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ä¸”å†…å®¹è¾ƒé•¿ï¼Œå¯èƒ½æ˜¯æœ€ç»ˆå›ç­”
        if "å·¥å…·" not in content and len(content) > 150:
            return True
        
        # è¶…è¿‡ä¸€å®šè½®æ¬¡ä¸”æ²¡æœ‰æ˜ç¡®çš„ä¸‹ä¸€æ­¥è®¡åˆ’
        if iteration >= 5 and not any(word in content for word in ["æ¥ä¸‹æ¥", "ç„¶å", "ä¸‹ä¸€æ­¥", "éœ€è¦"]):
            return True
        
        return False
    
    def _build_reasoning_summary(self, reasoning_steps: List[Dict], tool_calls: List[Dict]) -> str:
        """æ„å»ºæ¨ç†è¿‡ç¨‹æ€»ç»“"""
        
        summary_parts = []
        
        # æ·»åŠ æ€è€ƒè¿‡ç¨‹
        summary_parts.append("ğŸ§  æ€è€ƒè¿‡ç¨‹:")
        for i, step in enumerate(reasoning_steps, 1):
            if not step.get("error"):
                summary_parts.append(f"{i}. {step['thought'][:100]}{'...' if len(step['thought']) > 100 else ''}")
        
        # æ·»åŠ å·¥å…·ä½¿ç”¨
        if tool_calls:
            summary_parts.append("\nğŸ› ï¸ å·¥å…·ä½¿ç”¨:")
            for tool_call in tool_calls:
                status_icon = "âœ…" if tool_call["status"] == "success" else "âŒ"
                summary_parts.append(f"{status_icon} {tool_call['name']}: {tool_call.get('execution_time', 0)}ms")
        
        return "\n".join(summary_parts)
    
    async def _prepare_context(
        self, 
        agent: AdvancedAgent, 
        session: AgentSession, 
        message_history: List[Dict[str, Any]], 
        memory_enabled: bool
    ) -> Dict[str, Any]:
        """å‡†å¤‡å¯¹è¯ä¸Šä¸‹æ–‡"""
        
        context = {
            "recent_messages": message_history[-10:],  # æœ€è¿‘10æ¡æ¶ˆæ¯
            "available_tools": [],
            "relevant_memories": None,
            "knowledge_base": None
        }
        
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        if self.db:
            tools = self.db.query(AdvancedTool).filter(
                AdvancedTool.enabled == True
            ).all()
            
            # ç­›é€‰Agenté…ç½®çš„å·¥å…·
            agent_tools = agent.config.get("tools", [])
            available_tools = []
            
            for tool in tools:
                if tool.name in agent_tools:
                    available_tools.append(tool.name)
            
            context["available_tools"] = available_tools
        
        # è·å–ç›¸å…³è®°å¿†
        if memory_enabled and self.db:
            try:
                memories = await self.memory_manager.get_relevant_memories(
                    agent_id=str(agent.id),
                    query=message_history[-1]["content"] if message_history else "",
                    limit=5
                )
                
                if memories:
                    memory_text = "\n".join([f"- {mem['content']}" for mem in memories])
                    context["relevant_memories"] = memory_text
            except Exception as e:
                logger.warning(f"è·å–è®°å¿†å¤±è´¥: {e}")
        
        # è·å–çŸ¥è¯†åº“ä¿¡æ¯
        if agent.config.get("knowledge_base_enabled") and self.db:
            try:
                knowledge_items = self.db.query(AgentKnowledgeBase).filter(
                    AgentKnowledgeBase.agent_id == agent.id
                ).limit(5).all()
                
                if knowledge_items:
                    knowledge_text = "\n".join([f"- {item.title}: {item.content[:200]}..." for item in knowledge_items])
                    context["knowledge_base"] = knowledge_text
            except Exception as e:
                logger.warning(f"è·å–çŸ¥è¯†åº“å¤±è´¥: {e}")
        
        return context
    
    async def _get_available_tools(self, agent: AdvancedAgent) -> Optional[List[Dict[str, Any]]]:
        """è·å–Agentå¯ç”¨çš„å·¥å…·å®šä¹‰"""
        
        if not self.db:
            return None
        
        agent_tools = agent.config.get("tools", [])
        if not agent_tools:
            return None
        
        tools = self.db.query(AdvancedTool).filter(
            AdvancedTool.name.in_(agent_tools),
            AdvancedTool.enabled == True
        ).all()
        
        tool_definitions = []
        for tool in tools:
            tool_def = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.schema
                }
            }
            tool_definitions.append(tool_def)
        
        return tool_definitions if tool_definitions else None
    
    async def _get_model_config(self, model_id: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹é…ç½®"""
        
        if not self.db:
            raise ValueError("æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–")
        
        model = self.db.query(Model).filter(Model.id == model_id).first()
        if not model:
            raise ValueError(f"æ¨¡å‹ä¸å­˜åœ¨: {model_id}")
        
        return {
            "id": str(model.id),
            "name": model.name,
            "provider": model.provider,
            "endpoint": model.endpoint,
            "api_key": model.api_key,
            "custom_headers": model.custom_headers
        }
    
    async def _update_memory(
        self, 
        agent: AdvancedAgent, 
        session: AgentSession, 
        user_message: str, 
        agent_response: Dict[str, Any]
    ):
        """æ›´æ–°Agentè®°å¿†"""
        
        try:
            # ä¿å­˜å¯¹è¯è®°å¿†
            await self.memory_manager.save_conversation_memory(
                agent_id=str(agent.id),
                session_id=str(session.id),
                user_message=user_message,
                agent_response=agent_response["content"],
                confidence=agent_response.get("confidence", 0.5)
            )
            
            # å¦‚æœä½¿ç”¨äº†å·¥å…·ï¼Œä¿å­˜æŠ€èƒ½è®°å¿†
            if agent_response.get("tool_calls"):
                for tool_call in agent_response["tool_calls"]:
                    if tool_call["status"] == "success":
                        await self.memory_manager.save_skill_memory(
                            agent_id=str(agent.id),
                            tool_name=tool_call["name"],
                            usage_context=user_message,
                            success=True
                        )
        
        except Exception as e:
            logger.warning(f"æ›´æ–°è®°å¿†å¤±è´¥: {e}") 